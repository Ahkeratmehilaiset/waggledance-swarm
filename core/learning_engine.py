# WaggleDance Swarm AI â€¢ v0.0.3
# Jani Korpi (Ahkerat MehilÃ¤iset)
"""
LearningEngine â€” Suljettu oppimissilmukka
==========================================
Parven "aivot" jotka arvioivat, oppivat ja kehittyvÃ¤t.

ARKKITEHTUURI:
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚              LearningEngine                       â”‚
  â”‚                                                   â”‚
  â”‚  1. QualityGate                                   â”‚
  â”‚     â””â†’ 7b arvioi vastauksen laadun (1-10)         â”‚
  â”‚     â””â†’ Pisteet â†’ SwarmScheduler pheromone         â”‚
  â”‚     â””â†’ Pisteet â†’ TokenEconomy bonus/rangaistus    â”‚
  â”‚     â””â†’ HyvÃ¤t (7+) â†’ finetune_curated.jsonl       â”‚
  â”‚                                                   â”‚
  â”‚  2. PromptEvolver                                 â”‚
  â”‚     â””â†’ Vertaa parhaat vs huonoimmat agentit       â”‚
  â”‚     â””â†’ 7b ehdottaa parannuksia system promptiin   â”‚
  â”‚     â””â†’ A/B testaa: vanha vs uusi prompt           â”‚
  â”‚     â””â†’ Parempi jÃ¤Ã¤ voimaan                        â”‚
  â”‚                                                   â”‚
  â”‚  3. InsightDistiller                              â”‚
  â”‚     â””â†’ KerÃ¤Ã¤ parhaat oivallukset kaikista         â”‚
  â”‚     â””â†’ TiivistÃ¤Ã¤ â†’ jaettu tietopankki             â”‚
  â”‚     â””â†’ Relevanteille agenteille kontekstiin       â”‚
  â”‚                                                   â”‚
  â”‚  4. PerformanceTracker                            â”‚
  â”‚     â””â†’ Seuraa kuka paranee, kuka huononee         â”‚
  â”‚     â””â†’ Laukaisee PromptEvolver tarvittaessa       â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

MIKSI 7b (CPU/heartbeat-malli):
  - Arviointi on yksinkertainen tehtÃ¤vÃ¤ â†’ 7b riittÃ¤Ã¤
  - Ei kilpaile 32b:n kanssa GPU:sta
  - PyÃ¶rii taustalla, ei tarvitse olla nopea
  - OpsAgent voi pysÃ¤yttÃ¤Ã¤ jos kuorma kasvaa

ETIIKKA:
  - Ei muokkaa system prompteja ilman lokitusta
  - Kaikki muutokset tallentuvat audit-lokiin
  - AlkuperÃ¤iset promptit aina palautettavissa
"""

import asyncio
import json
import time
import logging
import statistics
from collections import deque, defaultdict
from dataclasses import dataclass, field
from pathlib import Path
from typing import Optional, Dict, List, Any, TYPE_CHECKING
from datetime import datetime

if TYPE_CHECKING:
    from core.swarm_scheduler import SwarmScheduler
    from core.token_economy import TokenEconomy

logger = logging.getLogger("waggle.learning")


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Tietorakenteet
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

@dataclass
class QualityScore:
    """Yhden vastauksen laadun arviointi."""
    agent_id: str
    agent_type: str
    score: float           # 1-10
    reasoning: str         # 7b:n perustelu
    prompt_preview: str
    response_preview: str
    timestamp: float = field(default_factory=time.monotonic)

    @property
    def is_good(self) -> bool:
        return self.score >= 7.0

    @property
    def is_bad(self) -> bool:
        return self.score < 4.0


@dataclass
class PromptExperiment:
    """A/B-testi: vanha vs uusi system prompt."""
    agent_id: str
    original_prompt: str
    evolved_prompt: str
    reason: str
    # Tulokset
    original_scores: list = field(default_factory=list)
    evolved_scores: list = field(default_factory=list)
    started_at: float = field(default_factory=time.monotonic)
    decided: bool = False
    winner: str = ""  # "original" | "evolved"

    @property
    def has_enough_data(self) -> bool:
        return len(self.original_scores) >= 3 and len(self.evolved_scores) >= 3


@dataclass
class AgentPerformance:
    """Agentin suorituskykyprofiili."""
    agent_id: str
    agent_type: str
    scores: deque = field(default_factory=lambda: deque(maxlen=50))
    # Trendit
    avg_7day: float = 5.0
    avg_recent: float = 5.0
    trend: float = 0.0          # +/- muutos
    total_evaluated: int = 0
    good_count: int = 0
    bad_count: int = 0
    # Prompt-evoluutio
    prompt_version: int = 0
    last_evolution: float = 0.0

    @property
    def good_rate(self) -> float:
        if self.total_evaluated == 0:
            return 0.0
        return self.good_count / self.total_evaluated

    @property
    def needs_help(self) -> bool:
        """Agentti tarvitsee prompt-evoluutiota."""
        return (self.total_evaluated >= 5
                and self.avg_recent < 5.0
                and self.trend <= 0)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Vakiot
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# Laadun arviointiin kÃ¤ytetty prompt
QUALITY_EVAL_PROMPT = """Arvioi seuraava AI-agentin vastaus asteikolla 1-10.

KRITEERIT:
- Relevanssi: Vastaako kysymykseen? (0-3 pistettÃ¤)
- Tarkkuus: Ovatko faktat oikein? (0-3 pistettÃ¤)
- HyÃ¶dyllisyys: Onko kÃ¤ytÃ¤nnÃ¶n apua? (0-2 pistettÃ¤)
- Selkeys: Onko helppolukuinen? (0-2 pistettÃ¤)

AGENTIN TYYPPI: {agent_type}
KYSYMYS/TEHTÃ„VÃ„: {prompt}
VASTAUS: {response}

Vastaa TASAN tÃ¤ssÃ¤ muodossa:
PISTEET: X/10
PERUSTELU: (1 lause)"""

# Prompt-evoluution ohje
PROMPT_EVOLVE_PROMPT = """Olet AI-jÃ¤rjestelmÃ¤n optimoija. Agentin "{agent_type}" system prompt
tuottaa heikkoja vastauksia (keskiarvo {avg_score:.1f}/10).

NYKYINEN SYSTEM PROMPT:
{current_prompt}

ESIMERKKEJÃ„ HUONOISTA VASTAUKSISTA:
{bad_examples}

ESIMERKKEJÃ„ HYVISTÃ„ VASTAUKSISTA (muilta agenteilta):
{good_examples}

Kirjoita PARANNETTU system prompt. SÃ¤ilytÃ¤:
- Agentin rooli ja erikoisala
- Suomen kieli
- Sama pituus (max 500 merkkiÃ¤)

Korjaa:
- EpÃ¤selvÃ¤t ohjeet
- Puuttuvat rajoitukset
- Liian yleiset neuvot

Vastaa VAIN uudella system promptilla, ei muuta."""

# Insight-tiivistyksen ohje
DISTILL_PROMPT = """TiivistÃ¤ nÃ¤mÃ¤ {n} oivallusta YHDEKSI tiiviiksi faktaksi (max 2 lausetta suomeksi).
Priorisoi: kÃ¤ytÃ¤nnÃ¶n hyÃ¶ty > teoria.

OIVALLUKSET:
{insights}

TIIVISTELMÃ„:"""


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# LearningEngine
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class LearningEngine:
    """
    Suljettu oppimissilmukka.

    KÃ¤yttÃ¤Ã¤ 7b (CPU/heartbeat) -mallia arviointiin.
    EI kilpaile 32b:n kanssa GPU:sta.
    OpsAgent voi pysÃ¤yttÃ¤Ã¤ jos kuorma liian kova.
    """

    def __init__(self, llm_evaluator, memory, scheduler=None,
                 token_economy=None, config: dict = None):
        """
        Args:
            llm_evaluator: 7b-malli (heartbeat LLM) â€” arviointiin
            memory: SharedMemory
            scheduler: SwarmScheduler â€” pheromone-pÃ¤ivitykset
            token_economy: TokenEconomy â€” bonus/rangaistus
            config: settings.yaml learning-osio
        """
        self.llm = llm_evaluator       # 7b CPU
        self.memory = memory
        self.scheduler = scheduler
        self.token_economy = token_economy
        self.config = config or {}

        # â”€â”€ Konfiguraatio â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        learn_cfg = self.config.get("learning", {})
        self.eval_queue_size = learn_cfg.get("eval_queue_size", 20)
        self.evolve_interval = learn_cfg.get("evolve_interval_min", 30)  # min
        self.distill_interval = learn_cfg.get("distill_interval_min", 15)
        self.min_score_for_finetune = learn_cfg.get("min_finetune_score", 7.0)
        self.auto_evolve_enabled = learn_cfg.get("auto_evolve", False)

        # â”€â”€ Tila â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        self.running = False
        self._task: Optional[asyncio.Task] = None
        self._eval_queue: deque = deque(maxlen=self.eval_queue_size)
        self._performances: Dict[str, AgentPerformance] = {}
        self._experiments: Dict[str, PromptExperiment] = {}
        self._quality_history: deque = deque(maxlen=200)
        self._cycle_count = 0

        # â”€â”€ Tiedostopolut â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        self._curated_path = Path("data/finetune_curated.jsonl")
        self._rejected_path = Path("data/finetune_rejected.jsonl")
        self._audit_path = Path("data/learning_audit.jsonl")
        self._curated_path.parent.mkdir(exist_ok=True)

        # â”€â”€ Tilastot â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        self.stats = {
            "total_evaluated": 0,
            "total_curated": 0,
            "total_rejected": 0,
            "total_evolutions": 0,
            "total_distillations": 0,
            "avg_quality": 0.0,
        }

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # Lifecycle
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    async def start(self):
        self.running = True
        self._task = asyncio.create_task(self._learning_loop())
        logger.info("LearningEngine kÃ¤ynnistetty")
        print("  âœ… LearningEngine (oppimissilmukka) kÃ¤ynnissÃ¤")

    async def stop(self):
        self.running = False
        if self._task:
            self._task.cancel()
            try:
                await self._task
            except asyncio.CancelledError:
                pass

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # Ulkoinen API: hivemind kutsuu jokaisen vastauksen jÃ¤lkeen
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    def submit_for_evaluation(self, agent_id: str, agent_type: str,
                               system_prompt: str, prompt: str,
                               response: str):
        """
        LisÃ¤Ã¤ vastaus arviointijonoon.
        Hivemind kutsuu tÃ¤tÃ¤ joka onnistuneen LLM-vastauksen jÃ¤lkeen.
        Evaluointi tapahtuu taustalla, ei blokkaa.
        """
        if not response or len(response.strip()) < 10:
            return

        self._eval_queue.append({
            "agent_id": agent_id,
            "agent_type": agent_type,
            "system_prompt": system_prompt[:500],
            "prompt": prompt[:500],
            "response": response[:500],
            "submitted_at": time.monotonic(),
        })

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # PÃ¤Ã¤silmukka
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    async def _learning_loop(self):
        """
        Oppimissykli:
          - Joka 30s: arvioi jonossa olevat vastaukset (7b)
          - Joka 15min: tiivistÃ¤ oivallukset
          - Joka 30min: ehdota prompt-parannuksia (jos auto_evolve)
        """
        while self.running:
            try:
                await asyncio.sleep(30)  # 30s sykli
                if not self.running:
                    break

                self._cycle_count += 1

                # 1. Arvioi jonossa olevat
                await self._evaluate_queue()

                # 2. Tarkista kokeet
                await self._check_experiments()

                # 3. TiivistÃ¤ oivallukset (joka 30. sykli = ~15min)
                if self._cycle_count % 30 == 0:
                    await self._distill_insights()

                # 4. Prompt-evoluutio (joka 60. sykli = ~30min)
                if (self.auto_evolve_enabled
                        and self._cycle_count % 60 == 0
                        and self._cycle_count > 0):
                    await self._evolve_weak_agents()

            except asyncio.CancelledError:
                break
            except Exception as e:
                logger.error(f"LearningEngine syklivirhe: {e}")

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # 1. QualityGate â€” Laadun arviointi
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    async def _evaluate_queue(self):
        """Arvioi max 3 vastausta per sykli (ei kuormita Ollamaa)."""
        evaluated = 0
        max_per_cycle = 3

        while self._eval_queue and evaluated < max_per_cycle:
            item = self._eval_queue.popleft()
            try:
                score = await self._evaluate_one(item)
                if score:
                    await self._process_score(score, item)
                    evaluated += 1
            except Exception as e:
                logger.warning(f"Evaluointi epÃ¤onnistui: {e}")

    async def _evaluate_one(self, item: dict) -> Optional[QualityScore]:
        """Arvioi yksi vastaus 7b:llÃ¤."""
        eval_prompt = QUALITY_EVAL_PROMPT.format(
            agent_type=item["agent_type"],
            prompt=item["prompt"][:300],
            response=item["response"][:300],
        )

        try:
            resp = await self.llm.generate(
                eval_prompt,
                system="Olet AI-vastausten laadun arvioija. Vastaa aina muodossa 'PISTEET: X/10'.",
                max_tokens=100,
                temperature=0.1
            )

            if not resp or resp.error or not resp.content:
                return None

            # Parsitaan pisteet
            score_val = self._parse_score(resp.content)
            if score_val is None:
                return None

            # Parsitaan perustelu
            reasoning = ""
            if "PERUSTELU:" in resp.content:
                reasoning = resp.content.split("PERUSTELU:")[-1].strip()[:200]

            return QualityScore(
                agent_id=item["agent_id"],
                agent_type=item["agent_type"],
                score=score_val,
                reasoning=reasoning,
                prompt_preview=item["prompt"][:100],
                response_preview=item["response"][:100],
            )

        except Exception as e:
            logger.warning(f"7b evaluointi virhe: {e}")
            return None

    def _parse_score(self, text: str) -> Optional[float]:
        """Parsii 'PISTEET: X/10' tekstistÃ¤."""
        import re
        # Etsii: 7/10, 8.5/10, PISTEET: 6/10
        matches = re.findall(r'(\d+(?:\.\d+)?)\s*/\s*10', text)
        if matches:
            val = float(matches[0])
            return max(1.0, min(10.0, val))

        # Fallback: pelkkÃ¤ numero
        matches = re.findall(r'(\d+(?:\.\d+)?)', text)
        if matches:
            val = float(matches[0])
            if 1 <= val <= 10:
                return val
        return None

    async def _process_score(self, score: QualityScore, item: dict):
        """KÃ¤sittele arvioitu vastaus: pÃ¤ivitÃ¤ kaikki jÃ¤rjestelmÃ¤t."""

        self._quality_history.append(score)
        self.stats["total_evaluated"] += 1

        # â”€â”€ A) PÃ¤ivitÃ¤ agentin suoritusprofiili â”€â”€â”€â”€â”€â”€â”€
        perf = self._performances.get(score.agent_id)
        if not perf:
            perf = AgentPerformance(
                agent_id=score.agent_id,
                agent_type=score.agent_type,
            )
            self._performances[score.agent_id] = perf

        perf.scores.append(score.score)
        perf.total_evaluated += 1
        if score.is_good:
            perf.good_count += 1
        if score.is_bad:
            perf.bad_count += 1

        # PÃ¤ivitÃ¤ keskiarvot
        all_scores = list(perf.scores)
        perf.avg_recent = statistics.mean(all_scores[-10:]) if all_scores else 5.0
        perf.avg_7day = statistics.mean(all_scores) if all_scores else 5.0
        if len(all_scores) >= 6:
            older = statistics.mean(all_scores[:-3])
            newer = statistics.mean(all_scores[-3:])
            perf.trend = newer - older
        else:
            perf.trend = 0.0

        # â”€â”€ B) PÃ¤ivitÃ¤ SwarmScheduler pheromone â”€â”€â”€â”€â”€â”€â”€
        if self.scheduler:
            self.scheduler.record_task_result(
                agent_id=score.agent_id,
                success=score.is_good,
                latency_ms=0,  # Ei mitattavissa jÃ¤lkikÃ¤teen
                had_corrections=score.is_bad,
            )

        # â”€â”€ C) TokenEconomy bonus/rangaistus â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        if self.token_economy:
            if score.score >= 9.0:
                await self.token_economy.reward(
                    score.agent_id, "excellent_quality",
                    custom_amount=15
                )
            elif score.score >= 7.0:
                await self.token_economy.reward(
                    score.agent_id, "good_quality",
                    custom_amount=5
                )
            elif score.score < 3.0:
                # Negatiivinen palaute: vÃ¤hennÃ¤ tokeneita
                await self.token_economy.spend(
                    score.agent_id, 3, "poor_quality_penalty"
                )

        # â”€â”€ D) Finetune-datan kuratointi â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        finetune_entry = {
            "messages": [
                {"role": "system", "content": item.get("system_prompt", "")},
                {"role": "user", "content": item["prompt"]},
                {"role": "assistant", "content": item["response"]},
            ],
            "agent_type": score.agent_type,
            "quality_score": score.score,
            "reasoning": score.reasoning,
            "timestamp": datetime.now().isoformat(),
        }

        if score.score >= self.min_score_for_finetune:
            self._append_jsonl(self._curated_path, finetune_entry)
            self.stats["total_curated"] += 1
        else:
            self._append_jsonl(self._rejected_path, finetune_entry)
            self.stats["total_rejected"] += 1

        # â”€â”€ E) Tallenna muistiin â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        if self.memory and score.score >= 8.0:
            await self.memory.store_memory(
                content=(f"[Laatuarvio] {score.agent_type}: "
                         f"{score.score}/10 â€” {score.reasoning}"),
                agent_id="learning_engine",
                memory_type="evaluation",
                importance=0.5,
            )

        # PÃ¤ivitÃ¤ kokonaiskeskiarvo
        recent = [s.score for s in list(self._quality_history)[-50:]]
        self.stats["avg_quality"] = statistics.mean(recent) if recent else 0

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # 2. PromptEvolver â€” System promptien kehitys
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    async def _evolve_weak_agents(self):
        """Etsi heikoimmat agentit ja ehdota parannuksia."""
        # Etsi agentit jotka tarvitsevat apua
        weak = [p for p in self._performances.values() if p.needs_help]
        if not weak:
            return

        # Etsi parhaiden esimerkkejÃ¤
        good_examples = self._get_good_examples(limit=3)

        for perf in weak[:2]:  # Max 2 evoluutiota kerrallaan
            # Ã„lÃ¤ kehitÃ¤ samaa agenttia liian usein
            if time.monotonic() - perf.last_evolution < self.evolve_interval * 60:
                continue

            # Ã„lÃ¤ tee jos koe jo kÃ¤ynnissÃ¤
            if perf.agent_id in self._experiments:
                continue

            bad_examples = self._get_bad_examples(perf.agent_id, limit=3)
            if not bad_examples:
                continue

            # Hae nykyinen system prompt muistista
            current_prompt = await self._get_agent_prompt(perf.agent_id)
            if not current_prompt:
                continue

            # 7b ehdottaa parannusta
            evolved = await self._generate_evolved_prompt(
                perf, current_prompt, bad_examples, good_examples
            )
            if not evolved:
                continue

            # Aloita A/B-koe
            experiment = PromptExperiment(
                agent_id=perf.agent_id,
                original_prompt=current_prompt,
                evolved_prompt=evolved,
                reason=f"avg={perf.avg_recent:.1f}, trend={perf.trend:+.1f}",
            )
            self._experiments[perf.agent_id] = experiment
            perf.last_evolution = time.monotonic()

            self._audit_log("prompt_experiment_started", {
                "agent_id": perf.agent_id,
                "reason": experiment.reason,
                "evolved_prompt_preview": evolved[:200],
            })

            self.stats["total_evolutions"] += 1
            logger.info(
                f"[LEARN] Prompt-koe aloitettu: {perf.agent_id} "
                f"(avg={perf.avg_recent:.1f}, trend={perf.trend:+.1f})"
            )
            print(f"  [LEARN] ğŸ§¬ Prompt-koe: {perf.agent_type} "
                  f"(laatu {perf.avg_recent:.1f}/10)")

    async def _generate_evolved_prompt(self, perf: AgentPerformance,
                                        current_prompt: str,
                                        bad_examples: str,
                                        good_examples: str) -> Optional[str]:
        """Generoi parannettu system prompt 7b:llÃ¤."""
        prompt = PROMPT_EVOLVE_PROMPT.format(
            agent_type=perf.agent_type,
            avg_score=perf.avg_recent,
            current_prompt=current_prompt[:500],
            bad_examples=bad_examples[:500],
            good_examples=good_examples[:500],
        )

        try:
            resp = await self.llm.generate(
                prompt,
                system="Olet AI-promptien optimoija. Vastaa VAIN uudella promptilla.",
                max_tokens=300,
                temperature=0.3,
            )
            if resp and not resp.error and resp.content:
                evolved = resp.content.strip()
                # Perusvalidointi
                if 50 < len(evolved) < 600 and evolved != current_prompt:
                    return evolved
        except Exception as e:
            logger.warning(f"Prompt-evoluutio epÃ¤onnistui: {e}")
        return None

    async def _check_experiments(self):
        """Tarkista kÃ¤ynnissÃ¤ olevat A/B-kokeet."""
        for agent_id, exp in list(self._experiments.items()):
            if exp.decided:
                continue

            # KerÃ¤Ã¤ pisteet tÃ¤mÃ¤n agentin viimeisistÃ¤ arvioinneista
            recent_scores = [
                s for s in self._quality_history
                if s.agent_id == agent_id
                and s.timestamp > exp.started_at
            ]

            # Jako: parilliset â†’ original, parittomat â†’ evolved
            # (yksinkertaistettu â€” oikeasti pitÃ¤isi vuorotella promptia)
            for i, s in enumerate(recent_scores):
                if i % 2 == 0:
                    exp.original_scores.append(s.score)
                else:
                    exp.evolved_scores.append(s.score)

            # Tarpeeksi dataa pÃ¤Ã¤tÃ¶kseen?
            if exp.has_enough_data:
                await self._decide_experiment(exp)

            # Timeout: 2h ilman pÃ¤Ã¤tÃ¶stÃ¤ â†’ peruuta
            if time.monotonic() - exp.started_at > 7200:
                exp.decided = True
                exp.winner = "original"  # Turvallinen oletus
                self._audit_log("prompt_experiment_timeout", {
                    "agent_id": agent_id,
                })

    async def _decide_experiment(self, exp: PromptExperiment):
        """PÃ¤Ã¤tÃ¤ A/B-koe: kumpi prompt voittaa?"""
        avg_orig = statistics.mean(exp.original_scores)
        avg_evolved = statistics.mean(exp.evolved_scores)

        # Evolved voittaa jos selkeÃ¤sti parempi (>0.5 pistettÃ¤)
        if avg_evolved > avg_orig + 0.5:
            exp.winner = "evolved"
            exp.decided = True

            # TODO: Vaihda agentin system prompt
            # TÃ¤mÃ¤ vaatii hivemind-integraation: agent.system_prompt = exp.evolved_prompt

            self._audit_log("prompt_experiment_won", {
                "agent_id": exp.agent_id,
                "avg_original": round(avg_orig, 1),
                "avg_evolved": round(avg_evolved, 1),
                "evolved_prompt": exp.evolved_prompt[:300],
            })
            logger.info(
                f"[LEARN] âœ… Evolved prompt VOITTI: {exp.agent_id} "
                f"({avg_orig:.1f} â†’ {avg_evolved:.1f})"
            )
            print(f"  [LEARN] âœ… Prompt parantunut: {exp.agent_id} "
                  f"({avg_orig:.1f} â†’ {avg_evolved:.1f})")
        else:
            exp.winner = "original"
            exp.decided = True
            self._audit_log("prompt_experiment_lost", {
                "agent_id": exp.agent_id,
                "avg_original": round(avg_orig, 1),
                "avg_evolved": round(avg_evolved, 1),
            })
            logger.info(
                f"[LEARN] âŒ Evolved prompt HÃ„VISI: {exp.agent_id} "
                f"({avg_orig:.1f} vs {avg_evolved:.1f})"
            )

        # Siivoa
        if exp.agent_id in self._experiments:
            del self._experiments[exp.agent_id]

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # 3. InsightDistiller â€” Oivalluksien tiivistys
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    async def _distill_insights(self):
        """
        KerÃ¤Ã¤ parhaat oivallukset ja tiivistÃ¤ ne.
        Tiivistetty tieto â†’ SharedMemory "distilled" -tyyppinÃ¤.
        """
        if not self.memory:
            return

        try:
            # Hae viimeisimmÃ¤t oivallukset
            all_memories = await self.memory.get_recent_memories(limit=30)
            insights = [
                m for m in all_memories
                if m.get("memory_type") == "insight"
                and m.get("content", "")
            ]

            if len(insights) < 5:
                return

            # Ryhmittele aiheen mukaan (yksinkertaistettu)
            insights_text = "\n".join([
                f"- [{m.get('agent_id', '?')}] {m['content'][:150]}"
                for m in insights[:15]
            ])

            # 7b tiivistÃ¤Ã¤
            resp = await self.llm.generate(
                DISTILL_PROMPT.format(n=min(len(insights), 15),
                                      insights=insights_text[:1000]),
                system="Olet tiedon tiivistÃ¤jÃ¤. Vastaa suomeksi, max 2 lausetta.",
                max_tokens=150,
                temperature=0.3,
            )

            if resp and not resp.error and resp.content:
                distilled = resp.content.strip()
                if len(distilled) > 20:
                    await self.memory.store_memory(
                        content=f"[Tiivistetty] {distilled}",
                        agent_id="learning_engine",
                        memory_type="distilled",
                        importance=0.9,
                    )
                    self.stats["total_distillations"] += 1
                    logger.info(f"[LEARN] Tiivistetty: {distilled[:100]}")

        except Exception as e:
            logger.warning(f"Insight-tiivistys epÃ¤onnistui: {e}")

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # Apufunktiot
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    def _get_good_examples(self, limit: int = 3) -> str:
        """Hae parhaiden arviointien vastausesimerkit."""
        good = sorted(
            [s for s in self._quality_history if s.score >= 8.0],
            key=lambda s: s.score, reverse=True
        )[:limit]
        if not good:
            return "(ei esimerkkejÃ¤ vielÃ¤)"
        return "\n".join([
            f"[{s.agent_type}, {s.score}/10]: {s.response_preview}"
            for s in good
        ])

    def _get_bad_examples(self, agent_id: str, limit: int = 3) -> str:
        """Hae agentin huonoimmat vastaukset."""
        bad = sorted(
            [s for s in self._quality_history
             if s.agent_id == agent_id and s.score < 5.0],
            key=lambda s: s.score
        )[:limit]
        if not bad:
            return ""
        return "\n".join([
            f"[{s.score}/10] Q: {s.prompt_preview} â†’ A: {s.response_preview}"
            for s in bad
        ])

    async def _get_agent_prompt(self, agent_id: str) -> Optional[str]:
        """Hae agentin nykyinen system prompt."""
        # YritetÃ¤Ã¤n hakea muistista
        if self.memory:
            try:
                cursor = await self.memory._db.execute(
                    "SELECT content FROM memories "
                    "WHERE agent_id = ? AND memory_type = 'system_prompt' "
                    "ORDER BY created_at DESC LIMIT 1",
                    (agent_id,)
                )
                row = await cursor.fetchone()
                if row:
                    return row[0]
            except Exception:
                pass
        return None

    def _append_jsonl(self, path: Path, entry: dict):
        """Kirjoita yksi rivi JSONL-tiedostoon."""
        try:
            with open(path, "a", encoding="utf-8") as f:
                f.write(json.dumps(entry, ensure_ascii=False) + "\n")
        except Exception:
            pass

    def _audit_log(self, event_type: str, data: dict):
        """Kirjoita audit-lokiin (kaikki muutokset jÃ¤ljitettÃ¤vissÃ¤)."""
        entry = {
            "type": event_type,
            "timestamp": datetime.now().isoformat(),
            "data": data,
        }
        self._append_jsonl(self._audit_path, entry)

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # Julkinen API
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    def get_status(self) -> dict:
        """Dashboard-tiedot."""
        perf_summaries = {}
        for aid, p in self._performances.items():
            perf_summaries[aid] = {
                "type": p.agent_type,
                "avg_recent": round(p.avg_recent, 1),
                "trend": round(p.trend, 2),
                "good_rate": round(p.good_rate, 2),
                "total_evaluated": p.total_evaluated,
                "needs_help": p.needs_help,
                "prompt_version": p.prompt_version,
            }

        experiments = {}
        for aid, exp in self._experiments.items():
            experiments[aid] = {
                "reason": exp.reason,
                "original_scores": len(exp.original_scores),
                "evolved_scores": len(exp.evolved_scores),
                "decided": exp.decided,
                "winner": exp.winner,
            }

        return {
            "running": self.running,
            "cycle_count": self._cycle_count,
            "queue_size": len(self._eval_queue),
            "auto_evolve": self.auto_evolve_enabled,
            "stats": self.stats,
            "agent_performance": perf_summaries,
            "experiments": experiments,
        }

    def get_leaderboard(self) -> list:
        """Agentit laadun mukaan."""
        return sorted(
            [
                {
                    "agent_id": p.agent_id,
                    "type": p.agent_type,
                    "avg_quality": round(p.avg_recent, 1),
                    "trend": round(p.trend, 2),
                    "good_rate": round(p.good_rate, 2),
                    "total": p.total_evaluated,
                }
                for p in self._performances.values()
                if p.total_evaluated >= 3
            ],
            key=lambda x: x["avg_quality"],
            reverse=True,
        )
